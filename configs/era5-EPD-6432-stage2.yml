log_dir: experiments/6432_epd_stage2_50k
device_ids: [0]
project_name: $your_project_name

model:

    base_dim: 256
    latent_dim: 512

    decoder:
        latent_dim: 256
        heads: 24
        dim_head: 64
        kernel_multiplier: 2
        use_distance_encoding: True
        use_softmax: False
        qk_norm: True

    processor:
        latent_dim: 256
        heads: 16
        dim_head: 64
        kernel_multiplier: 2
        use_distance_encoding: True
        use_softmax: False
        qk_norm: True
        depth: 6

    l_spherical_harmonics: 20  # 36 bases in total

    pivot_ratio: 2


data:
    data_dir: $your_data_dir
    interval: 1    # 6 hrs
    valsteps: 29    # 168 hrs
    val_timestamps: [ 1, 12, 20, 28 ]
    nlat: 32
    nlon: 64
    years_range: [1990, 2015]


    constant_names: ['land_sea_mask',
                    'angle_of_sub_gridscale_orography',
                    'anisotropy_of_sub_gridscale_orography',
                    'soil_type']
    variable_groups: [
                      ['2m_temperature', 'mean_sea_level_pressure', '10m_u_component_of_wind', '10m_v_component_of_wind'],
                      [ 'total_precipitation_6hr', 'total_precipitation_24hr'],
                      ['u_component_of_wind', 'v_component_of_wind', 'specific_humidity',
                       'temperature', 'geopotential'],
                      ]
    variable_levels:  [1, 1, 1, 1, 1, 1,
                       13, 13,
                       13, 13, 13,
                       ]

    surface_variable_weight: [1., 0.1, 0.1, 0.1, 0.05, 0.05]
    multi_level_variable_weight: [0.5, 0.5, 0.1, 1.0, 1.0]


training:
    lr: 3.e-7
    beta_1: 0.9
    beta_2: 0.95
    weight_decay: 1.e-6
    warmup_steps: 1000
    max_steps: 50000
    warmup_start_lr: 1.e-8
    eta_min: 1.e-7
    global_batch_size: 16
    val_batch_size: 32
    ckpt_every: 10000
    print_every: 20
    validate_every: 10000
    train_num_workers: 4

    smooth_l1_beta: 0.01
    level_weight: linear
    max_grad_norm: 4.0

    curriculum_values: [4, 8, 12, 16, 20]
    curriculum_milestone: [0, 10000, 20000, 30000, 40000]
    gradient_checkpointing_segment_size: 1

    use_compile: False   # this doesn't work for gradient checkpointing

    pretrained_checkpoint_path: experiments/6432_epd_stage1_160k/model/model_160k_iter.pth
    ema_checkpoint: none
    resume_checkpoint_path: none
    resume_from_checkpoint: False
    ema_decay: 0.999